\section{Introduction}
\label{sct:introduction}

% TODO count lines of code in LMS based DSLs (hyper) where stage distinction is relevant.

% TODO better citations metaOCaml, interpreters to compilers, DSLs
 Multi-stage programming (or \emph{staging}) is a flavor of meta-programming where compilation is
  separated in multiple \emph{stages} of compilation. Execution of each stage outputs
  the code that is executed in the next stage of compilation. Notable, staging frameworks
  are MetaOCaml~\cite{taha_multi-stage_1997} and LMS~\cite{rompf2012lightweight}.
  Staging has been mostly used for \emph{partial evaluation}~\cite{jones1993partial}
  and successfully applied for: removing abstraction overheads in high-level
  programs~\cite{carette2005multi,rompf2012lightweight}, domain-specific
  languages~\cite{jonnalagedda2014staged}, and converting language
  interpreters into compilers~\cite{lancet}.

The compilation stage in which a term is executed is determined by code
 quotations~(in MetaOCaml) or by parametric types \code{Rep}~(in LMS). We show an
 example of staging on a function for computing an inner product of
 vectors~\footnotemark[1]:\begin{lstparagraph}
  def dot[V:Numeric](v1: Vector[V], v2: Vector[V]): V =
    (v1 zip v2).foldLeft(zero[V]) {
      case (prod, (cl, cr)) => prod + cl * cr
    }
 \end{lstparagraph}

If the vector sizes are known during program runtime the inner product can
 be partially evaluated into a sum of products of vector components.
 In LMS~\footnotemark[2] we communicate that the vector size is known by annotating
 only vector elements with a \code{Rep} type:\begin{lstparagraph}
  def dot[V:Numeric]
    (v1: Vector[Rep[V]], v2: Vector[Rep[V]]): Rep[V]
 \end{lstparagraph}

Here the \code{Rep} annotations on \code{V} denote that elements of vectors will be known
 only in the next stage (after runtime compilation). At this stage the \code{zip}
 \code{foldLeft}, and pattern matching inside the closure will not exist
 as they were evaluated at the previous stage (host language runtime).

% Host language compile-time, run-time, all frameworks execute at runtime.
% All types/terms in future stages require annotations.

What would happen if vector sizes were known at the compile-time of the host language?
All the code that is executing in the host language executed at the program

Let's observe what happens when we have multiple annotation
%  \item Programming languages Idris and D allow placing the \code{static}
%   annotation on function arguments. Since \code{static} is placed on terms rather
%   then types, it denotes that the \emph{whole term} is static. This restricts the number of programs
%   that can be expressed, \eg, we could not express that vectors in the signature of \emph{dot}
%   are partially static.
% MacroML
% % For all notable common frameworks the starting stage is the runtime



% % Seldom Used -> should not change programs at run-time.
% % Should be able to evaluate at host-language compile-time.




% % The main idea of this paper is that staging should be possible for compile-time
% % values and that non-staged programs should remain unmodified.

% \begin{itemize}
%  \item Programming languages Idris and D allow placing the \code{static}
%   annotation on function arguments. Since \code{static} is placed on terms rather
%   then types, it denotes that the \emph{whole term} is static. This restricts the number of programs
%   that can be expressed, \eg, we could not express that vectors in the signature of \emph{dot}
%   are partially static.

%  \item Lightweight Modular Staging (LMS)~\cite{rompf2012lightweight} uses types to communicate
%   the programmer's intent about partial evaluation. By changing the types of parameters
%   to be (\eg \code{Vector[Rep[T]]} these approaches can express that parameter vectors
%   are statically known. However, they still require existence of two data structures
%   (\eg \code{Rep[Vector]} and \code{Vector}. This fosters costly and hardly maintainable
%   code duplication.

%  \item MetaOCaml~\cite{taha_multi-stage_1997} places terms in, possibly nested,
%    quotes. Depth of the term in the quotes denotes the stage of the computation
%    where it will be executed. In MetaOCaml we can express the \code{dot} function,
%    but we have to modify the code of the \code{dot} function which might not be desirable.

% \end{itemize}

Ideally, a programmer would with a minimal number of annotations be able to:
 \emph{i)} require that input vectors are of statically known size but polymorphic
  in their elements, \emph{ii)} without modifying the terms require that all operations
  on vector arguments are further partially evaluated, \emph{iii)} allow elements
  of vectors to be generic, and \emph{iv)} reuse the existing implementation of
  the \code{Vector} data structure.

The main idea of this paper is to provide a statically typed \emph{compile-time
 view} of existing data types. The compile-time view makes all operations and
 non-generic fields partially evaluated on a type. The compile-time view allows
 programmers to define a single definition of a type. Then the existing types
 can be promoted to their compile-time duals with the \code{@ct} annotation at
 the type level, and with the \code{ct} function on the term level.
 Consequently, due to the integration with the type system, the control over
 partial evaluation is fine-grained and polymorphic and term level promotions
 obviate code duplication for static data structures.

With our partial evaluator, to require that vectors \code{v1} and \code{v2} are
 static and to partially evaluate the function, a programmer would need to make
 a simple modification of the \code{dot} signature:\begin{lstparagraph}
  def dot[V: Numeric]
    (v1: Vector[V]@ct, v2: Vector[V]@ct): V
\end{lstparagraph}

This, in effect, requires that only vector arguments (not their elements) are
 statically known and that all operations on vector arguments will be executed
 at compile time (partially evaluated). Since, values are polymorphic the result
 of the function will either be a dynamic value or a compile-time value. Residual
 programs of \code{dot} application for different arguments:

\vspace{1.8mm}
\begin{listing}[mathescape]
  // [el1, el2, el3, el4] are dynamic
  dot(ct(Vector)(el1, el2), ct(Vector)(el3, el4))
    $\hookrightarrow$ el1 * el3 + el2 * el4

  dot(ct(Vector)(2, 4), ct(Vector)(1, 10))
    $\hookrightarrow$ 2 * 1 + 4 * 10

  // ct promotes static terms to compile-time
  dot(ct(Vector)(ct(2), ct(4)), ct(Vector)(ct(1), ct(10)))
    $\hookrightarrow$ 42
\end{listing}
\vspace{1.8mm}

In this paper we make the following contributions to the state of the art:
\begin{itemize}

 \item By introducing the \calculus calculus (\sct{sct:calculus}) that in a
  fine-grained way captures the user's intent about partial evaluation. The calculus
  is based on $F_{<:}$ with lazy records which makes it suitable for representing
  modern multi-paradigm languages with object oriented features. Finally,
  we formally define a partial evaluator for \calculus.

 \item By providing a \emph{translation scheme} from data types in object oriented languages
  (polymorphic classes and methods) into their dual compile-time views in the
  \calculus calculus (\sct{sct:scala-translation}).

 \item By demonstrating the usefulness of compile-time views in four case
 studies (\sct{sct:case-studies}): inlining, partially evaluating recursion,
 removing overheads of variable argument functions, and removing overheads of
 type-classes~\cite{oliveira2010type}.

\end{itemize}

We have implemented a partial evaluator according to the translation scheme (\sct{sct:scala-translation})
 from object oriented features of Scala to the \calculus calculus. The partial is
 implemented for Scala and open-sourced (\url{https://github.com/scala-inline/}).
 It has a minimal Scala interface (\sct{sct:interface}) based on type annotations.
 We have evaluated the performance gains and the validity of the partial evaluator
 on all case studies (\sct{sct:case-studies}) and compared them to LMS. In all benchmarks
 our evaluator gives significant performance gains compared to original programs and
 performs equivalently to LMS.




% \emph{Partial evaluation}~\cite{jones1993partial} is an optimization technique
% that identifies \emph{statically known} program parts and pre-computes them at
% compile time. The compile-time computation yields a \emph{residual program} that
% does not contain the, previously identified, statically known parts of the
% program. Partial evaluation has been intensively studied and successfully
% applied for: removing abstraction overheads in high-level
% programs~\cite{carette2005multi,rompf2012lightweight}, domain-specific
% languages~\cite{brady2010,jonnalagedda2014staged}, and converting language
% interpreters into compilers~\cite{futamura1999partial,lancet,wurthinger2013one}.
% Applying partial evaluation in these domains often improves program performance
% by several orders of magnitude~\cite{shali2011Hybrid,brady2010}.

% Unlike other compiler optimizations partial evaluation is not \emph{safe}: it
%  might lead to \emph{code explosion} and might not \emph{terminate}. Due to
%  compile-time execution,  computing \code{fold}s and loops over data structures
%  of static size can produce arbitrarily large residual programs. Furthermore, in a
%  Turing-complete language assuring termination of partial-evaluation is undecidable. \todo{cite}

% Automatically assuring safety of partial evaluators necessarily leads to
%  lack of \emph{predictability}. To illustrate, let us define a function
%  \code{dot} for computing a dot-product of two vectors that contain numeric values\footnotemark[1]:\begin{lstparagraph}
%   def dot[V:Numeric](v1: Vector[V], v2: Vector[V]): V =
%     (v1 zip v2).foldLeft(zero[V]){ case (prod, (cl, cr)) =>
%       prod + cl * cr
%     }
% \end{lstparagraph}

% When \code{dot} is called with vectors of static size (\eg \code{dot(Vector(2,
%  4), Vector(1, 10))}) the abstraction overhead of \code{zip} and \code{foldLeft}
%  can be completely removed. However, the partial evaluator must apply extensive
%  analysis to conclude that vectors are of static size and that this information
%  can be later used to unroll the recursion inside \code{foldLeft}. Even if the analysis is
%  successful the evaluator must be conservative about unrolling the
%  \code{foldLeft}. The vector sizes, and thus the produced code, can unacceptably
%  large in a general case. What if we know that vector sizes are relatively small
%  and we would like to predictably unroll \code{dot} into a flat sum of products?


% Lack of predictability and danger of code explosion are the reason that
%  successful partial evaluators
%  \cite{brady2010,taha_multi-stage_1997,rompf2012lightweight,wurthinger2013one,le2004specialization}
%   are programmer controlled. We categorize the existing solutions in three categories
%  (for further discussion \cf \sct{sct:related-work}):

% \begin{itemize}
%  \item Programming languages Idris and D provide allow placing the \code{static}
%   annotation on function arguments. Since \code{static} is placed on terms, it
%   denotes that the \emph{whole term} is static. This restricts the number of programs
%   that can be expressed, \eg, we could not express that vectors in the signature of \emph{dot}
%   are partially static.

%  \item Type-directed partial evaluation~\cite{danvy1999type} and
%   Lightweight Modular Staging (LMS)~\cite{rompf2012lightweight} use types to communicate
%   the programmer's intent about partial evaluation. By changing the types of parameters
%   to be (\eg \code{Vector[Rep[T]]} these approaches can express that parameter vectors
%   are statically known. However, they still require existence of two data structures
%   (\eg \code{Rep[Vector]} and \code{Vector}. This fosters costly and hardly maintainable
%   code duplication.

%  \item MetaOCaml~\cite{taha_multi-stage_1997} places terms in, possibly nested,
%    quotes. Depth of the term in the quotes denotes the stage of the computation
%    where it will be executed. In MetaOCaml we can express the \code{dot} function,
%    but we have to modify the code of the \code{dot} function which might not be desirable.

% \end{itemize}


% Ideally, a programmer would with a minimal number of annotations be able to:
%  \emph{i)} require that input vectors are of statically known size but polymorphic
%   in their elements, \emph{ii)} without modifying the terms require that all operations
%   on vector arguments are further partially evaluated, \emph{iii)} allow elements
%   of vectors to be generic, and \emph{iv)} reuse the existing implementation of
%   the \code{Vector} data structure.

% The main idea of this paper is to provide a statically typed \emph{compile-time
%  view} of existing data types. The compile-time view makes all operations and
%  non-generic fields partially evaluated on a type. The compile-time view allows
%  programmers to define a single definition of a type. Then the existing types
%  can be promoted to their compile-time duals with the \code{@ct} annotation at
%  the type level, and with the \code{ct} function on the term level.
%  Consequently, due to the integration with the type system, the control over
%  partial evaluation is fine-grained and polymorphic and term level promotions
%  obviate code duplication for static data structures.

% With our partial evaluator, to require that vectors \code{v1} and \code{v2} are
%  static and to partially evaluate the function, a programmer would need to make
%  a simple modification of the \code{dot} signature:\begin{lstparagraph}
%   def dot[V: Numeric](v1: Vector[V] @ct, v2: Vector[V] @ct): V
% \end{lstparagraph}

% This, in effect, requires that only vector arguments (not their elements) are
%  statically known and that all operations on vector arguments will be executed
%  at compile time (partially evaluated). Since, values are polymorphic the result
%  of the function will either be a dynamic value or a compile-time value. Residual
%  programs of \code{dot} application for different arguments:

% \vspace{1.8mm}
% \begin{listing}[mathescape]
%   // [el1, el2, el3, el4] are dynamic
%   dot(ct(Vector)(el1, el2), ct(Vector)(el3, el4))
%     $\hookrightarrow$ el1 * el3 + el2 * el4

%   dot(ct(Vector)(2, 4), ct(Vector)(1, 10))
%     $\hookrightarrow$ 2 * 1 + 4 * 10

%   // ct promotes static terms to compile-time
%   dot(ct(Vector)(ct(2), ct(4)), ct(Vector)(ct(1), ct(10)))
%     $\hookrightarrow$ 42
% \end{listing}
% \vspace{1.8mm}

% In this paper we make the following contributions to the state-of-the-art:
% \begin{itemize}

%  \item By introducing the \calculus calculus (\sct{sct:calculus}) that in a fine-
%  grained way captures the user's intent about partial evaluation. The calculus
%  is based on $F_{<:}$ with lazy records which makes it suitable for representing
%  modern multi-paradigm languages with object oriented features. Finally,
%  we formally define a partial evaluator for \calculus.

%  \item By providing a \emph{translation scheme} from data types in object oriented languages
%   (polymorphic classes and methods) into their dual compile-time views in the
%   \calculus calculus (\sct{sct:scala-translation}).

%  \item By demonstrating the usefulness of compile-time views in four case
%  studies (\sct{sct:case-studies}): inlining, partially evaluating recursion,
%  removing overheads of variable argument functions, and removing overheads of
%  type-classes~\cite{oliveira2010type}.

% \end{itemize}

% We have implemented a partial evaluator according to the translation scheme (\sct{sct:scala-translation})
%  from object oriented features of Scala to the \calculus calculus. The partial is
%  implemented for Scala and open-sourced (\url{https://github.com/scala-inline/}).
%  It has a minimal Scala interface (\sct{sct:interface}) based on type annotations.
%  We have evaluated the performance gains and the validity of the partial evaluator
%  on all case studies (\sct{sct:case-studies}) and compared them to LMS. In all benchmarks
%  our evaluator gives significant performance gains compared to original programs and
%  performs equivalently to LMS.
